<!DOCTYPE html>
<!-- Authors: Crystal T Chang -->
<html lang="en">
<head>
  <meta name="generator" content="HTML Tidy for HTML5 for Linux version 5.7.16">
  <meta charset="utf-8">
  <title>Evaluating Anti-LGBTQIA+ Medical Bias in Large Language Models (LLMs)</title>
  <meta name="description" content="Investigating the potential of LLMs to propagate anti-LGBTQIA+ medical bias and misinformation."><!--#include file="lagunita.html" -->
  <!--Lagunita Theme (TODO: Server side include)-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="lagunita/css/bootstrap.min.css" type="text/css">
  <link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" type="text/css">
  <link rel="stylesheet" href="lagunita/css/base.min.css?v=0.1" type="text/css">
  <link rel="stylesheet" href="lagunita/css/custom.css?v=0.1" type="text/css">
  <!--End Lagunita Theme-->
  <link rel="icon" type="image/ico" href="favicon.ico">
</head>
<body class="site-slogan">
  <!--#include file="header.html" -->
  <!--Header (TODO: Server side include)-->
  <div id="top">
    <div class="container">
      <!--=== Skip links ===-->
      <div id="skip">
        <a href="#content" onclick="$('#content').focus()">Skip to content</a>
      </div><!-- /Skip links -->
    </div>
  </div>
  <div id="brandbar">
    <div class="container">
      <a href="http://www.stanford.edu"><img src="lagunita/images/brandbar-stanford-logo%402x.png" alt="Stanford University" width="152" height="23"></a>
    </div><!-- .container end -->
  </div>
  <div id="header" class="clearfix" role="banner">
    <div class="container">
      <div class="row">
        <div class="col-md-8">
          <div id="signature">
            <div id="site-name">
              <a href="https://echonet.github.io/dynamic/index.html"><span id="site-name-1">Evaluating Anti-LGBTQIA+ Medical Bias in Large Language Models (LLMs)</span></a>
            </div>
            <div id="site-slogan">
              <a href="https://echonet.github.io/dynamic/index.html"><span id="site_slogan">Investigating the potential of LLMs to propagate anti-LGBTQIA+ medical bias and misinformation.</span></a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div><!-- Menu -->
  <div id="mainmenu" class="clearfix" role="navigation">
    <div class="container">
      <div class="navbar navbar-default">
        <!-- main navigation -->
         <button type="button" class="navbar-toggle btn-navbar" data-toggle="collapse" data-target=".navbar-collapse"> <span class="menu-text">Menu</span></button> <!-- /nav-collapse -->
        <div class="navbar-collapse collapse">
          <div role="navigation">
            <div id="primary-nav">
              <ul class="nav navbar-nav" aria-label="primary navigation">
                <li id="nav-1">
                  <a href="index.html">Home</a>
                </li>
                <li id="nav-2">
                  <a href="index.html#intro">Introduction</a>
                </li>
                <li id="nav-3">
                  <a href="index.html#methods">Methods</a>
                </li>
                <li id="nav-4">
                  <a href="index.html#dataset">Dataset</a>
                </li>
                <li id="nav-5">
                  <a href="index.html#code">Code</a>
                </li>
                <li id="nav-6">
                  <a href="index.html#access">Accessing Dataset</a>
                </li>
                <li id="nav-7">
                  <a href="index.html#paper">Paper</a>
                </li>
              </ul>
            </div>
          </div>
        </div><!-- /nav-collapse -->
      </div><!-- /navbar -->
    </div><!-- /container -->
  </div><!-- /mainmenu -->
  <!--End Header-->
  <div id="intro" class="container" role="introduction" tabindex="0">
    <h2>Introduction</h2>
    <p>From drafting responses to patient messages in electronic health record systems to clinical decision support, Large Language Models (LLMs) present many opportunities for use in medicine. Patient-facing use-cases are also relevant, such as a patient using an LLM to obtain information on potential treatments for a medical issue. In these applications, it is important to consider potential harms to minority groups through the propagation of medical misinformation or misconceptions. Leading LLMs propagate harmful and debunked notions of race-based medicine and binary gender bias. This has been explored in the context of prompting LLMs directly with questions relating to race-based medical misconceptions6 and through incorporating race-identifying information into clinical notes and investigating how the presence of this information can lead to bias and inaccuracy. </p><br>
    <p>Though the presence of anti-LGBTQIA+ bias and inaccuracy has long been suspected in LLMs tasked with medical use cases, our study is the first to investigate this across multiple real-world clinical scenarios in cooperation with clinical experts. We include both explicit questions, which mimic the use of LLMs as a search tool, and extended clinical scenarios, which simulate medical scenarios through realistic patient notes. We also probe for both incidental bias associated only with the mention of the LGBTQIA+ identity and expected historical bias surrounding stereotyped medical conditions, and thoroughly classify and qualitatively annotate inaccuracies at a level of detail not captured by previous numerical-only evaluations of bias. We test both publicly accessible LLMs, which have been previously shown to be used by community clinicians, and a secure model intended for clinical use.</p>
    <br>
    <p><h2 id="methods">Methods</h2>
    <p>In order to train and test AI algorithms in dermatology, we need diverse, validated benchmarks. We curated the Diverse Dermatology Images (DDI) dataset to meet this need—the first publicly available, deeply curated, and pathologically confirmed image dataset with diverse skin tones.</p><br>
    <br>
    <p><b>Clinical application:</b> Given the long wait time to see a dermatologist, AI algorithms could help triage benign versus malignant lesions.  However, it is important to have expertly labeled data that represents diverse skin tones in order to make sure that algorithms perform fairly across all groups. </p>
    <br>
    <p><img class="center" loading="lazy" width="500" src="media/JAMA_derm_diverse.png">
    <p><h2 id="dataset">Dataset</h2>
    <p> <b>Labeling:</b> The DDI was retrospectively selected from reviewing pathology reports in Stanford Clinics from 2010-2020 with further details in our paper. There are 656 images representing 570 unique patients.  Each image label was expertly curated: skin tone was labeled based on in-person evaluation at the clinic visit cross-referenced against demographic photos and review of the clinical images by two board certified dermatologists. Each diagnosis was based on pathology reports from biopsy: these reports and the corresponding image was reviewed by a board certified dermatologist and dermatopathologist.  </p><br>
    <p><b>Skin tone comparison:</b> The dataset comprised a retrospective convenience sample across all images of Fitzpatrick I-VI but was also designed to allow direct comparison between Fitzpatrick I-II and Fitzpatrick V-VI by matching diagnostic category, age within 10 years, gender, and date of photograph within 3 years. The images are not meant to be text book examples but rather represent the kind of clinical photos that AI algorithms may encounter in practice.  This design allows us to evaluate previously developed state-of-the-art diagnostic algorithms across. During the de-identification process prior to data release, some of the images were cropped further to protect patient privacy.  However, the main lesions were preserved during this process.</p><br>
    <p><img class="center" loading="lazy" width="500" src="media/Figure_1_modified.png">
  
    <p>Further description of the dataset is available in our <a href="https://arxiv.org/abs/2111.08006">NeurIPS Machine Learning 4 Health workshop extended abstract</a>.</p>
    <br>
    <h2 id="code">Code</h2>
    <p>Our code is available <a href="https://drive.google.com/drive/folders/1oQ53WH_Tp6rcLZjRp_-UBOQcMl-b1kkP?usp=sharing">here</a>.</p>
    <br>
    <h2 id="access">Accessing Dataset</h2>
    <br>
    <div class="well" id="agreement" tabindex="0">
      <h2>Stanford University School of Medicine Diverse Dermatology Images Dataset Research Use Agreement</h2>
      <p>By registering for downloads from the Diverse Dermatology Images Dataset, you are agreeing to this Research Use Agreement, as well as to the Terms of Use of the Stanford University School of Medicine website as posted and updated periodically at http://www.stanford.edu/site/terms/.</p>
      <p>1. Permission is granted to view and use the Diverse Dermatology Images Dataset without charge for personal, non-commercial research purposes only. Any commercial use, sale, or other monetization is prohibited.</p>
      <p>2. Other than the rights granted herein, the Stanford University School of Medicine (“School of Medicine”) retains all rights, title, and interest in the Diverse Dermatology Images Dataset.</p>
      <p>3. You may make a verbatim copy of the Diverse Dermatology Images Dataset for personal, non-commercial research use as permitted in this Research Use Agreement. If another user within your organization wishes to use the Diverse Dermatology Images Dataset, they must register as an individual user and comply with all the terms of this Research Use Agreement.</p>
      <p>4. YOU MAY NOT DISTRIBUTE, PUBLISH, OR REPRODUCE A COPY of any portion or all of the Diverse Dermatology Images Dataset to others without specific prior written permission from the School of Medicine.</p>
      <p>5. YOU MAY NOT SHARE THE DOWNLOAD LINK to the Diverse Dermatology Images dataset to others. If another user within your organization wishes to use the Diverse Dermatology Images Dataset, they must register as an individual user and comply with all the terms of this Research Use Agreement.</p>
      <p>6. You must not modify, reverse engineer, decompile, or create derivative works from the Diverse Dermatology Images Dataset. You must not remove or alter any copyright or other proprietary notices in the Diverse Dermatology Images Dataset.</p>
      <p>7. The Diverse Dermatology Images Dataset has not been reviewed or approved by the Food and Drug Administration, and is for non-clinical, Research Use Only. In no event shall data or images generated through the use of the Diverse Dermatology Images Dataset be used or relied upon in the diagnosis or provision of patient care.</p>
      <p>8. THE Diverse Dermatology Images DATASET IS PROVIDED "AS IS," AND STANFORD UNIVERSITY AND ITS COLLABORATORS DO NOT MAKE ANY WARRANTY, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE, NOR DO THEY ASSUME ANY LIABILITY OR RESPONSIBILITY FOR THE USE OF THIS Diverse Dermatology Images DATASET.</p>
      <p>9. You will not make any attempt to re-identify any of the individual data subjects. Re-identification of individuals is strictly prohibited. Any re-identification of any individual data subject shall be immediately reported to the School of Medicine.</p>
      <p>10. Any violation of this Research Use Agreement or other impermissible use shall be grounds for immediate termination of use of this Diverse Dermatology Images Dataset. In the event that the School of Medicine determines that the recipient has violated this Research Use Agreement or other impermissible use has been made, the School of Medicine may direct that the undersigned data recipient immediately return all copies of the Diverse Dermatology Images Dataset and retain no copies thereof even if you did not cause the violation or impermissible use.</p>
      <p>In consideration for your agreement to the terms and conditions contained here, Stanford grants you permission to view and use the Diverse Dermatology Images Dataset for personal, non-commercial research. You may not otherwise copy, reproduce, retransmit, distribute, publish, commercially exploit or otherwise transfer any material.</p>
      <h4>Limitation of Use</h4>
      <p>You may use Diverse Dermatology Images Dataset for legal purposes only.</p>
      <p>You agree to indemnify and hold Stanford harmless from any claims, losses or damages, including legal fees, arising out of or resulting from your use of the Diverse Dermatology Images Dataset or your violation or role in violation of these Terms. You agree to fully cooperate in Stanford’s defense against any such claims. These Terms shall be governed by and interpreted in accordance with the laws of California.</p>
    </div>
    
    <div class="well" id="access" tabindex="0">
    <a href="https://stanfordaimi.azurewebsites.net/datasets/834e1cd1-92f7-4268-9daa-d359198b310a">Access the dataset via the Stanford Artificial Intelligence in Medicine and Imaging (AIMI) Center Shared Datasets Portal.</a><br>
    </div>
    
    <br>
    <br>
      <h2 id="paper">Paper</h2>
      <p><a href="https://doi.org/10.1038/s41586-020-2145-8">***preprint here***</a><br><b>Roxana Daneshjou</b>, <b>Kailas Vodrahalli</b>, Weixin Liang, Roberto A Novoa, Melissa Jenkins, Veronica Rotemberg, Justin Ko, Susan M Swetter, Elizabeth E Bailey, Olivier Gevaert, Pritam Mukherjee, Michelle Phung, Kiana Yekrang, Bradley Fong, Rachna Sahasrabudhe, <b>James Zou</b>, <b>Albert Chiou</b>. <b>arXiv</b> (2022) </p>
      <p>For inquiries, contact us at <a href="mailto:%20roxanad@stanford.edu">roxanad@stanford.edu</a>.</p>

  </div>
  <!--Lagunita Theme (TODO: Server side include)-->
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
  <script src="lagunita/js/modernizr.custom.17475.js"></script>
  <script src="lagunita/js/bootstrap.min.js"></script>
  <script src="lagunita/js/base.js?v=1.0"></script>
  <script src="lagunita/js/custom.js"></script>
  <!--End Lagunita Theme-->
</body>
</html>
